# app.py
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import re
import torch
import joblib
import requests
import shap
import matplotlib.pyplot as plt
from io import BytesIO
from transformers import AutoTokenizer, AutoModel
from paddleocr import PaddleOCR
import os
import requests

ocr = PaddleOCR(use_angle_cls=True, lang='ch')

# ------------------ é¡µé¢è®¾ç½® ------------------
st.set_page_config(page_title="å†å…¥ICUé£é™©é¢„æµ‹å·¥å…· - ReAdmit", layout="wide")
st.markdown("""
<style>
/* é¡µé¢æ•´ä½“å­—ä½“å¤§å°å’Œé—´è· */
body, .css-18e3th9, .stApp {
    font-size: 0.9rem;  /* è°ƒæ•´æ•´ä½“å­—ä½“ */
    line-height: 1.2;
}

/* æ ‡é¢˜å­—ä½“ */
h1, h2, h3, h4, h5, h6 {
    font-size: 1.2rem;
}

/* è¾“å…¥æ¡†å’ŒæŒ‰é’®å­—ä½“ */
.stTextInput>div>input, .stNumberInput>div>input, .stButton>button, .stSelectbox>div>div {
    font-size: 0.9rem;
    padding: 0.25rem 0.4rem;
}

/* è¡¨æ ¼å­—ä½“ */
.stTable td, .stTable th {
    font-size: 0.85rem;
}
</style>
""", unsafe_allow_html=True)

# ------------------ æ¨¡å‹åŠ è½½ ------------------
@st.cache_resource
def load_models():
    base_path = os.getcwd()
    model = joblib.load(os.path.join(base_path, "model_0922.joblib"))
    with open(os.path.join(base_path, "pca_model.pkl"), "rb") as f:
        pca = pickle.load(f)
    with open(os.path.join(base_path, "threshold_0922.txt"), "r") as f:
        threshold = float(f.read().strip())
    tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
    bert_model = AutoModel.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
    return model, pca, threshold, tokenizer, bert_model

model, pca, threshold, tokenizer, bert_model = load_models()
ocr = PaddleOCR(use_angle_cls=True, lang='ch')

# ------------------ LLM åœ¨çº¿è°ƒç”¨ ------------------
def ask_deepseek_online(prompt):
    url = "https://api.deepseek.com/chat/completions"
    headers = {
        "Authorization": f"Bearer {os.getenv('DEEPSEEK_API_KEY')}",  # åœ¨éƒ¨ç½²ç¯å¢ƒé…ç½®API Key
        "Content-Type": "application/json"
    }
    payload = {
        "model": "deepseek-chat",   # æˆ– deepseek-reasonerï¼Œæ ¹æ®ä½ éœ€è¦çš„æ¨¡å‹
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåŒ»å­¦åŠ©æ‰‹ï¼Œæä¾›é£é™©è§£è¯»å’Œä¸´åºŠå»ºè®®ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=60)
        r.raise_for_status()
        data = r.json()
        return data["choices"][0]["message"]["content"].strip()
    except Exception as e:
        return f"LLMè°ƒç”¨å¤±è´¥ï¼š{e}"

# ------------------ æ–‡æœ¬é¢„å¤„ç† ------------------
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s:=\.\(\)/]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def generate_embeddings(text):
    text = clean_text(text)
    inputs = tokenizer(text, return_tensors="pt", max_length=512, truncation=True, padding="max_length")
    with torch.no_grad():
        outputs = bert_model(**inputs)
    embeddings = outputs.last_hidden_state[:, 0, :].squeeze().numpy()
    return embeddings

# ------------------ OCR æå–æ–‡æœ¬å¹¶æ ‡å‡†åŒ– ------------------
def extract_text_from_image(image_file):
    with open("temp_report.png", "wb") as f:
        f.write(image_file.getvalue())
    result = ocr.ocr("temp_report.png", cls=True)
    full_text = " ".join([line[1][0] for line in result[0]])

    # ---- æ–‡æœ¬æ ‡å‡†åŒ– ----
    full_text = full_text.upper()
    full_text = re.sub(r"\s+", " ", full_text).strip()
    full_text = full_text.replace("âº", "+").replace("ï¼", "-").replace("â€“", "-")
    full_text = full_text.replace("ï¼","0").replace("ï¼‘","1").replace("ï¼’","2").replace("ï¼“","3")
    full_text = full_text.replace("ï¼”","4").replace("ï¼•","5").replace("ï¼–","6").replace("ï¼—","7")
    full_text = full_text.replace("ï¼˜","8").replace("ï¼™","9")
    full_text = full_text.replace("HC03", "HCO3")

    # ---- å»é™¤å‚è€ƒå€¼ç‰‡æ®µ ----
    full_text = re.sub(r"å‚è€ƒå€¼?\s*[:ï¼š]?\s*-?\d+\.?\d*\s*-\s*\d+\.?\d*", "", full_text)
    full_text = re.sub(r"\(\s*-?\d+\.?\d*\s*-\s*\d+\.?\d*\s*\)", "", full_text)

    return full_text

# ------------------ æ£€éªŒæŒ‡æ ‡æå– ------------------
def extract_lab_values(text):
    alias_map = {
       "wbc": ["ç™½ç»†èƒ", "WBC"], "rbc": ["çº¢ç»†èƒ", "RBC"],
        "hemoglobin": ["è¡€çº¢è›‹ç™½", "HGB"], "hematocrit": ["çº¢ç»†èƒå‹ç§¯", "HCT"],
        "mch": ["å¹³å‡è¡€çº¢è›‹ç™½å«é‡", "MCH"], "platelet": ["è¡€å°æ¿", "PLT"],
        "rdw": ["çº¢ç»†èƒåˆ†å¸ƒå®½åº¦CV", "RDW_CV"], "alt": ["ä¸™æ°¨é…¸æ°¨åŸºè½¬ç§»é…¶", "ALT"],
        "ast": ["å¤©å†¬æ°¨é…¸æ°¨åŸºè½¬ç§»é…¶", "AST"], "albumin": ["ç™½è›‹ç™½", "ALB"],
        "bilirubin_total": ["æ€»èƒ†çº¢ç´ ", "TBIL", "T-BIL"], "creatinine": ["è‚Œé…", "CR", "CREA"],
        "sodium": ["é’ ", "NA\\+", "é’ ç¦»å­", "Na\\+?"], "potassium": ["é’¾", "K\\+?", "é’¾ç¦»å­"],
        "chloride": ["æ°¯", "CL-?", "æ°¯ç¦»å­", "Cl\\-", "CL"], "calcium": ["é’™", "CA\\+\\+?", "CA2\\+", "Ca"],
        "bicarbonate": ["HCO3-", "ç¢³é…¸æ°¢æ ¹", "ç¢³é…¸æ°¢ç›", "HCO3-ï¼ˆstdï¼‰"], "glucose": ["è‘¡è„ç³–", "GLU", "Glu"],
        "lactate": ["ä¹³é…¸", "LAC", "Lac"], "ph": ["PH"], "be": ["ç¢±å‰©ä½™", "SBE", "BE"],
        "pao2": ["æ°§åˆ†å‹", "PO2", "PAO2"], "paco2": ["äºŒæ°§åŒ–ç¢³åˆ†å‹", "PACO2", "PCO2"],
        "inr": ["å›½é™…æ ‡å‡†æ¯”ç‡", "INR"], "pt": ["PT", "å‡è¡€é…¶åŸæ—¶é—´"], "ptt": ["APTT", "æ´»åŒ–éƒ¨åˆ†å‡è¡€æ´»é…¶"]
    }
    results = {}
    for standard_name, aliases in alias_map.items():
        for alias in aliases:
            pattern = rf"{alias}[^\d\-]{{0,6}}(-?\d+(?:\.\d+)?)(?!\s*-\s*\d)"
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                results[standard_name] = float(match.group(1))
                break
    return results

# ------------------ Charlson æŒ‡æ•° ------------------
def calculate_charlson_score(age, selections):
    score = 0
    weights = {"group1": 1, "group2": 2, "group3": 3, "group4": 6}
    for group, items in selections.items():
        score += weights[group] * len(items)
    if age >= 40:
        score += ((age - 40) // 10) + 1
    return score

# ------------------ SHAP è§£é‡Š ------------------
def predict_with_shap(model, structured_array, bert_pca_vec):
    X = np.hstack([structured_array, bert_pca_vec])
    prob = float(model.predict_proba(X)[0][1])

    try:
        explainer = shap.Explainer(model)
        shap_values = explainer(X)   # è¿™é‡Œä¼ å…¥å•ä¸ªæ ·æœ¬ä¹Ÿå¯ä»¥
        vals = shap_values.values[0]
        
        # å¦‚æœæ²¡æœ‰ feature_namesï¼Œå°±è‡ªå·±ç”Ÿæˆ
        feature_names = shap_values.feature_names
        if feature_names is None:
            feature_names = [f"feature_{i}" for i in range(X.shape[1])]

        idx = np.argsort(-np.abs(vals))[:10]
        top_features = [(feature_names[i], float(vals[i])) for i in idx]

        plt.figure(figsize=(6, 4))
        shap.plots.bar(shap_values[0], max_display=10, show=False)
        buf = BytesIO()
        plt.savefig(buf, format="png", bbox_inches="tight")
        buf.seek(0)
        plt.close()
        return prob, top_features, buf
    except Exception as e:
        print("SHAP è®¡ç®—å¤±è´¥:", e)
        return prob, [], None

# ------------------ é¡µé¢ UI ------------------
st.title("å†å…¥ICU é£é™©é¢„æµ‹å·¥å…· - ReAdmit")
st.warning("âš ï¸ ä¸Šä¼ æŠ¥å‘Šæˆªå›¾/ç…§ç‰‡å‰è¯·åŠ¡å¿…éšå»æ•æ„Ÿä¿¡æ¯ã€‚")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

with st.form("icu_form"):
    col1, col2, col3, col4 = st.columns(4, gap="small")

    # åŸºæœ¬ä¿¡æ¯
    with col1:
        st.subheader("ğŸ“ åŸºæœ¬ä¿¡æ¯")
        age = st.number_input("å¹´é¾„ï¼ˆå²ï¼‰", min_value=0, max_value=120)
        gender = st.radio("æ€§åˆ«", options=["ç”·", "å¥³"])
        gender_score = 1 if gender == "ç”·" else 0
        los_hospital = st.number_input("ä½é™¢æ—¶é•¿ï¼ˆå¤©ï¼‰")
        los_icu = st.number_input("ICUä½é™¢æ—¶é•¿ï¼ˆå¤©ï¼‰")

    # ç”Ÿå‘½ä½“å¾
    with col2:
        st.subheader("â¤ï¸ ç”Ÿå‘½ä½“å¾")
        hr = st.number_input("å¿ƒç‡ï¼ˆæ¬¡/åˆ†ï¼‰")
        sbp = st.number_input("æ”¶ç¼©å‹ï¼ˆmmHgï¼‰")
        dbp = st.number_input("èˆ’å¼ å‹ï¼ˆmmHgï¼‰")
        mbp = (sbp + 2 * dbp) / 3 if sbp and dbp else 0
        st.number_input("å¹³å‡åŠ¨è„‰å‹ï¼ˆmmHgï¼‰è‡ªåŠ¨è®¡ç®—", value=mbp, disabled=True)
        spo2 = st.number_input("è¡€æ°§é¥±å’Œåº¦ (%)")
        temp = st.number_input("ä½“æ¸©ï¼ˆâ„ƒï¼‰")

    # å…¶ä»–ä½“å¾
    with col3:
        st.subheader("ğŸŒ¡ å…¶ä»–ä½“å¾")  
        urine = st.number_input("æœ€å24hå°¿é‡ï¼ˆmlï¼‰")
        o2flow = st.number_input("å¸æ°§æµé‡ï¼ˆL/minï¼‰")
        intubated = st.radio("æ˜¯å¦æœ‰æ°”ç®¡æ’ç®¡æˆ–åˆ‡å¼€", options=["æœ‰", "æ— "])
        intubation_flag = 1 if intubated == "æœ‰" else 0
        mech_time = st.number_input("æœºæ¢°é€šæ°”æ—¶é•¿ï¼ˆå°æ—¶ï¼‰")

    # Charlson åˆå¹¶ç—‡
    with col4:
        st.subheader("ğŸ§¾ Charlson åˆå¹¶ç—‡é€‰æ‹©")
        group1 = st.multiselect("1 åˆ†ç±»ï¼ˆ1åˆ†ï¼‰", ["å¿ƒè‚Œæ¢—æ­»","å……è¡€æ€§å¿ƒåŠ›è¡°ç«­","å‘¨å›´è¡€ç®¡ç–¾ç—…","è„‘è¡€ç®¡ç–¾ç—…","ç—´å‘†","æ…¢æ€§è‚ºéƒ¨ç–¾ç—…","ç»“ç¼”ç»„ç»‡ç—…","æºƒç–¡ç—…","è½»åº¦è‚è„ç–¾ç—…","ç³–å°¿ç—…"])
        group2 = st.multiselect("2 åˆ†ç±»ï¼ˆ2åˆ†ï¼‰", ["åç˜«","ä¸­åº¦å’Œé‡åº¦è‚¾è„ç–¾ç—…","ç³–å°¿ç—…ä¼´æœ‰å™¨å®˜æŸå®³","åŸå‘æ€§è‚¿ç˜¤","ç™½è¡€ç—…","æ·‹å·´ç˜¤"])
        group3 = st.multiselect("3 åˆ†ç±»ï¼ˆ3åˆ†ï¼‰", ["ä¸­åº¦å’Œé‡åº¦è‚è„ç–¾ç—…"])
        group4 = st.multiselect("6 åˆ†ç±»ï¼ˆ6åˆ†ï¼‰", ["è½¬ç§»æ€§è‚¿ç˜¤","è·å¾—æ€§å…ç–«ç¼ºé™·ç»¼åˆå¾ï¼ˆè‰¾æ»‹ç—…ï¼‰"])
        selections = {"group1": group1, "group2": group2, "group3": group3, "group4": group4}
        charlson_score = calculate_charlson_score(age, selections)
        st.success(f"Charlson åˆå¹¶ç—‡æŒ‡æ•°ï¼ˆå«å¹´é¾„åŠ æƒï¼‰: {charlson_score}")

    # ---------- æ£€éªŒæŠ¥å‘Šä¸Šä¼ ï¼ˆå…¨å®½ï¼‰ ----------
    st.subheader("ğŸ§ª ä¸Šä¼ æ£€éªŒæŠ¥å‘Š")
    col_u1, col_u2, col_u3, col_u4 = st.columns(4, gap="small")
    with col_u1:
        cbc_images = st.file_uploader("è¡€å¸¸è§„", type=["png","jpg","jpeg"], accept_multiple_files=True)
    with col_u2:
        liver_kidney_images = st.file_uploader("è‚è‚¾åŠŸ/ç”ŸåŒ–", type=["png","jpg","jpeg"], accept_multiple_files=True)
    with col_u3:
        coag_images = st.file_uploader("å‡è¡€", type=["png","jpg","jpeg"], accept_multiple_files=True)
    with col_u4:
        abg_images = st.file_uploader("è¡€æ°”åˆ†æ", type=["png","jpg","jpeg"], accept_multiple_files=True)

    # æ”¾å°„å­¦æ£€æŸ¥
    st.subheader("ğŸ“· æ”¾å°„å­¦æ£€æŸ¥")
    no_radiology = st.checkbox("æœªè¿›è¡Œæ”¾å°„å­¦æ£€æŸ¥")
    report_image = st.file_uploader("æœ€è¿‘ä¸€æ¬¡æ”¾å°„å­¦æŠ¥å‘Šæˆªå›¾", type=["png","jpg","jpeg"], disabled=no_radiology)

    submitted = st.form_submit_button("ğŸ” è¿›è¡Œé£é™©é¢„æµ‹")
    
    
# ------------------ é¢„æµ‹ ------------------
if submitted:
    try:
        embeddings_reduced = np.zeros((1, 768))
        if not no_radiology and report_image:
            extracted_text = extract_text_from_image(report_image)
            st.info(f"æå–åˆ°çš„æ”¾å°„å­¦æŠ¥å‘Šæ–‡æœ¬ï¼š{extracted_text[:100]}...")
            embeddings = generate_embeddings(extracted_text)
            embeddings_reduced = pca.transform([embeddings])

        # å®éªŒå®¤æŒ‡æ ‡æå–
        lab_values = {}
        lab_groups = {
            "cbc": ["wbc","rbc","hemoglobin","hematocrit","mch","platelet","rdw"],
            "liver_kidney": ["creatinine","alt","ast","albumin","bilirubin_total"],
            "coag": ["inr","pt","ptt"],
            "abg": ["ph","be","pao2","paco2","lactate","bicarbonate","calcium",
                        "chloride","glucose","sodium","potassium"]
        }

        def extract_and_store(image_files, keys, label):
            combined_text = " "
            if image_files:
                for img in image_files:
                    combined_text += extract_text_from_image(img) + " "
                extracted = extract_lab_values(combined_text)
                for key in keys:
                    if key in extracted:
                        lab_values[key] = extracted[key]
                st.success(f"{label} æå–æŒ‡æ ‡å¦‚ä¸‹ï¼š")
                st.write({k: lab_values[k] for k in keys if k in lab_values})

        extract_and_store(cbc_images, lab_groups["cbc"], "è¡€å¸¸è§„")
        extract_and_store(liver_kidney_images, lab_groups["liver_kidney"], "è‚è‚¾åŠŸ/ç”ŸåŒ–æ£€éªŒ")
        extract_and_store(coag_images, lab_groups["coag"], "å‡è¡€æ£€éªŒ")
        extract_and_store(abg_images, lab_groups["abg"], "è¡€æ°”åˆ†æ")



        # æ„é€ æ¨¡å‹è¾“å…¥
        # ------------------ å•ä½æ¢ç®— ------------------
        unit_conversion = {
            "hemoglobin": 0.1,
            "creatinine": 88.4,
            "albumin": 0.1,
            "bilirubin_total": 17.1,
            "glucose": 55.51,
            "calcium": 2
            }

# ä¸ä¿®æ”¹æ˜¾ç¤ºï¼Œåªåœ¨æ¨¡å‹è¾“å…¥æ—¶æ¢ç®—
        lab_values_for_model = lab_values.copy()
        for key, factor in unit_conversion.items():
            if key in lab_values_for_model:
                lab_values_for_model[key] = lab_values_for_model[key] * factor
        
        
        lab_features = lab_groups["cbc"] + lab_groups["liver_kidney"] + lab_groups["coag"] + lab_groups["abg"]
        lab_inputs = [lab_values_for_model.get(name, 0) for name in lab_features]
        input_values = np.array([
                age, gender_score, los_hospital, los_icu, hr, sbp, dbp, mbp, spo2, temp,
                urine, o2flow, intubation_flag, mech_time, charlson_score
        ] + lab_inputs).reshape(1, -1)
        final_input = np.hstack([input_values, embeddings_reduced])

        # é¢„æµ‹ + SHAP
        prob, top_features, shap_buf = predict_with_shap(model, input_values, embeddings_reduced)
        result = "è‡ªICUè½¬å‡ºåˆ°ç—…æˆ¿å72å°æ—¶å†å…¥ICUçš„é£é™©è¾ƒé«˜" if prob >= threshold else "è‡ªICUè½¬å‡ºåˆ°ç—…æˆ¿å72å°æ—¶å†å…¥ICUçš„é£é™©è¾ƒä½"
        st.subheader("ğŸ“Š é¢„æµ‹ç»“æœ")
        st.write(f"é£é™©åˆ†ç±»ç»“æœï¼š**{result}**")

        st.subheader("ğŸ” SHAP è§£é‡Š")
        if top_features:
            st.table([{ "feature": f, "shap_value": v } for f, v in top_features])
        if shap_buf:
            st.image(shap_buf)
       
        # LLM å»ºè®®
        # -------- æ•´ç†æ‚£è€…ä¿¡æ¯ --------
        patient_summary = f"""
        åŸºæœ¬ä¿¡æ¯:
        - å¹´é¾„: {age} å²
        - æ€§åˆ«: {gender}
        - ä½é™¢æ—¶é•¿: {los_hospital} å¤©
        - ICUä½é™¢æ—¶é•¿: {los_icu} å¤©

        ç”Ÿå‘½ä½“å¾:
        - å¿ƒç‡: {hr} æ¬¡/åˆ†
        - è¡€å‹: {sbp}/{dbp} mmHg (å¹³å‡åŠ¨è„‰å‹ {mbp:.1f})
        - è¡€æ°§é¥±å’Œåº¦: {spo2}%
        - ä½“æ¸©: {temp} â„ƒ
        - 24hå°¿é‡: {urine} ml
        - å¸æ°§æµé‡: {o2flow} L/min
        - æ°”ç®¡æ’ç®¡/åˆ‡å¼€: {"æ˜¯" if intubation_flag else "å¦"}
        - æœºæ¢°é€šæ°”æ—¶é•¿: {mech_time} å°æ—¶

        Charlson åˆå¹¶ç—‡æŒ‡æ•°ï¼ˆå«å¹´é¾„åŠ æƒï¼‰: {charlson_score}
        å…·ä½“åˆå¹¶ç—‡:
        - 1åˆ†ç±»: {", ".join(group1) if group1 else "æ— "}
        - 2åˆ†ç±»: {", ".join(group2) if group2 else "æ— "}
        - 3åˆ†ç±»: {", ".join(group3) if group3 else "æ— "}
        - 6åˆ†ç±»: {", ".join(group4) if group4 else "æ— "}

        å®éªŒå®¤æ£€éªŒæŒ‡æ ‡:
        """  

        # -------- åŠ å…¥å®éªŒå®¤æŒ‡æ ‡ --------
        if lab_values:
            for k, v in lab_values.items():
                patient_summary += f"- {k}: {v}\n"
        else:
            patient_summary += "- æœªæå–åˆ°å®éªŒå®¤æŒ‡æ ‡\n"

        # -------- æ¨¡å‹é¢„æµ‹ & SHAP --------
        patient_summary += f"\næ¨¡å‹é¢„æµ‹ç»“æœ: {result}\n"

        shap_text = "\n".join([f"{i+1}. {f}: {v:.3f}" for i, (f, v) in enumerate(top_features)])

        prompt = f"""
        æ‚£è€…æƒ…å†µå¦‚ä¸‹:
        {patient_summary}

        æ¨¡å‹é¢„æµ‹ç»“æœ: {result} 
        ä¸»è¦è´¡çŒ®ç‰¹å¾ (SHAP æ’åå‰åˆ—): 
        {shap_text}

        è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯æä¾›:
        1. ç®€è¦è§£é‡Šé£é™©ç»“æœï¼ˆç»“åˆæ‚£è€…çš„ä¸´åºŠç‰¹å¾ã€å®éªŒå®¤æ£€æŸ¥å’Œåˆå¹¶ç—‡æƒ…å†µï¼‰
        2. ä¸‰æ¡å¯è¡Œçš„ä¸´åºŠå¹²é¢„å»ºè®®ï¼ˆæ¯æ¡é™„ç®€çŸ­ç†ç”±ï¼‰
        3. ä¸‰ç¯‡ç›¸å…³æ–‡çŒ®ï¼ˆæ ‡é¢˜ + æœŸåˆŠ + å¹´ä»½ï¼‰
        """
        advice = ask_deepseek_online(prompt)
        st.subheader("ğŸ¤– LLM å»ºè®®")
        st.markdown(advice)

        st.session_state["messages"].append({"role":"assistant","content":advice})

    except Exception as e:
        st.error(f"é¢„æµ‹å‡ºé”™: {e}")

# ------------------ å¤šè½®å¯¹è¯ ------------------
st.subheader("ğŸ’¬ ä¸åŠ©æ‰‹ç»§ç»­å¯¹è¯")
user_q = st.text_input("è¾“å…¥ä½ çš„è¿½é—®ï¼š")
if st.button("å‘é€é—®é¢˜"):
    if user_q:
        st.session_state["messages"].append({"role":"user","content":user_q})
        history_prompt = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state["messages"]])
        resp = ask_deepseek_online(history_prompt)
        st.session_state["messages"].append({"role":"assistant","content":resp})
        st.write(resp)
